<!doctype html>

<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1024" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <title>Neural Networks</title>

    <link href="//fonts.googleapis.com/css?family=Open+Sans:regular,semibold,italic,italicsemibold|PT+Sans:400,700,400italic,700italic|PT+Serif:400,700,400italic,700italic" rel="stylesheet" />

    <link href="css/impress-demo.css" rel="stylesheet" />
    
    <link rel="shortcut icon" href="favicon.png" />
    <link rel="apple-touch-icon" href="apple-touch-icon.png" />
</head>

<body class="impress-not-supported">

<div class="fallback-message">
    <p>Your browser <b>doesn't support the features required</b> by impress.js, so you are presented with a simplified version of this presentation.</p>
    <p>For the best experience please use the latest <b>Chrome</b>, <b>Safari</b> or <b>Firefox</b> browser.</p>
</div>

<div id="impress" data-autoplay="7">

    <div id="title" class="step" data-x="0" data-y="0" data-scale="4" >
        <h1>Neural Networks</h1>
        <div>Sina Sarparast {ss4g17@soton.ac.uk}istory </div>
        <div>Chun Hei Fok {chf1n17@soton.ac.uk}</div>
    </div>

    <div id="History1" class="step slide" data-x="-1700" data-y="-1500" data-autoplay="0" >
        	<h1>History</h1>
        	<br>	
        	<p>
        	<b>In 1943</b>, McCulloch and Pitts wrote a paper on how neurons might work. They modeled a simple neural network using electrical circuits.</p>
        	<br>
        	<p>
        		<b>In 1949</b>, Hebb wrote <i>"The Organization of Behavior"</i>, a work which pointed out the fact that neural pathways are strengthened each time they are used, a concept fundamentally essential to the ways, in which human learn.
        	</p>
        
        
    </div>

    <div id="History2" class="step slide" data-x="-700" data-y="-1500" data-autoplay="0" >
        	<h1>History</h1>
        	<br>	
        	<p>
        		<b>In 1949s</b>, a paper was written that suggested there could not be an extension from the single layered neural network to a multiple layered neural network. 
        		<!-- In addition, many people in the field were using a learning function that was fundamentally flawed because it was not differentiable across the entire line. As a result, research and funding went drastically down. -->
        	</p>
        	<br>
        	<p>
        		<b>In 1982</b>, interest in the field was renewed. Hopfield used bidirectional lines. Previously, the connections between neurons was only one way.
        	</p>
        	<br>
        	<p>
        		<b>In 1986</b>, Rumelhart came up with back propagation networks. 
        	</p>
        
        
    </div>

    <div id="WhatIsANeuralNetwork?" class="step slide" data-x="300" data-y="-1500">
        <h1>What is a neural network?</h1>
        	<br>
        	<ul>
        		<li>Neurons and connections between them just like human brain</li>
        		<br>
        		<li>There is Billions of nerve cells (neurons)
        		 and trillions of interconnections in the human brain </li>
        	</ul>
    </div>

    <div id="ANeuronIs" class="step slide" data-x="1300" data-y="-1500">
        <h1>A Neuron is …</h1>
        <br>
        	<img src="neuron.png" alt="" class="image" >
    </div>

    <div id="MimickingANeuronsFunction" class="step" data-x="00" data-y="2400" data-scale="4">
        <h1>Mimicking a neuron’s function</h1></q>
        <img class="image" src="ArtificialNeuron.png" alt="">
    </div>

    <div id="MultiLayerPerceptron" class="step" data-x="3700" data-y="2500" data-rotate="-90" data-scale="5">
        <h1>Multi Layer Perceptron</h1>
        <img class="image" src="MLP.png" alt="">
    </div>


    <div id="SomeFeaturesOfMLP" class="step" data-x="3000" data-y="-850" data-rotate="270" data-scale="2">
        <!-- <p>by <b class="positioning">positioning</b>, <b class="rotating">rotating</b> and <b class="scaling">scaling</b> them on an infinite canvas</p> -->
        <h1>Some Features of MLP</h1>
        <p>
        	<ul>
	        	<li>MLPs consist of three or more layers of nodes</li>
	        	<li>MLPs are fully connected</li>
				<li>MLP is a class of feedforward artificial neural networks (ANNs)</li>
        	</ul>
        </p>
    </div>

    <div id="InputLayer" class="step" data-x="7000" data-y="-500" data-scale="6">
        <h1>Input Layer</h1>
        <p>Input layer simply emits input Zi</p>
    </div>

    <div id="OutputLayer" class="step" data-x="7000" data-y="600" data-scale="6">
        <h1>Output Layer</h1>
        <p>Has specific number of neurons.<br>
        Ex: 10 if we have can have 10 different outputs</p>
    </div>

    <div id="HiddenLayers" class="step" data-x="7200" data-y="-650" data-z="700" data-rotate-x="90" data-scale="6">
    	<h1>Hidden Layers</h1>
        <p>each neuron in the hidden layer uses a non-linear activation function</p>
    </div>

    <div id="ActivationFunctions" class="step" data-x="7000" data-y="1800" data-rotate-y="-40" data-scale="4">
        <h1>Activation Functions</h1>
        <ul>
        	<li>The activation function in a neural network is a function used to transform the activation level of a unit (neuron) into an output signal.</li>
        	<li>The activation function essentially divides the original space into typically two partitions, having a "squashing" effect. </li>
        </ul>
    </div>

    <div id="Feedforward-Neural-Network" class="step" data-x="4000" data-y="-850"  data-rotate="270" data-scale="2">
		<h1>Feedforward Neural Network</h1>
		<p>A feedforward neural network is an artificial neural network wherein connections between the units do not form a cycle.</p>
    </div>

    <div id="Recurrent-neural-network" class="step" data-x="4000" data-y="1000" data-z="-4000" data-scale="1">
		<h1>Recurrent Neural Network</h1>
		<p>A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This allows it to exhibit dynamic temporal behavior.</p>
    </div>

    <div id="Backpropagation1" class="step" data-x="-1000" data-y="5000" data-scale="4" data-rotate-y="40">
		<h1>Backpropagation</h1>
		<p>Backpropagation is a method used in artificial neural networks to calculate the error contribution of each neuron after a batch of data (in image recognition, multiple images) is processed</p>
    </div>

    <div id="Backpropagation2" class="step" data-x="0" data-y="1000" data-z="-5000" data-rotate-y="90" data-scale="1">
		<h1>Backpropagation</h1>
		<p>Hybrid networks used just two layers, these back-propagation networks use many. The result is that back-propagation networks are "slow learners," needing possibly thousands of iterations to learn.</p>
    </div>

    <div id="Resources" class="step" data-x="8000" data-y="5000" data-rotate-y="-20" data-scale="3">
		<h1>Resources</h1>
		<ul>
			<li>https://secure.ecs.soton.ac.uk/notes/comp6229/l7_neuralnetworks.pdf</li>
			<li>https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html</li>
		</ul>
    </div>

    <div id="overview" class="step" data-x="3000" data-y="1500" data-z="0" data-scale="10">
    </div>

</div>

<div id="impress-toolbar"></div>

<!-- <div class="hint">
    <p>Use a spacebar or arrow keys to navigate. <br/>
       Press 'P' to launch speaker console.</p>
</div>
<script>
if ("ontouchstart" in document.documentElement) { 
    document.querySelector(".hint").innerHTML = "<p>Swipe left or right to navigate</p>";
}
</script> -->

<script src="js/impress.js"></script>
<script>impress().init();</script>

</body>
</html>


